{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# File operations\n",
    "from copy import deepcopy\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Stats\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import spearmanr, wilcoxon, mannwhitneyu\n",
    "import statsmodels.stats.multitest\n",
    "\n",
    "# Neuromaps\n",
    "import neuromaps\n",
    "from neuromaps.parcellate import Parcellater\n",
    "from neuromaps import datasets, images, nulls, resampling\n",
    "from nibabel import freesurfer as fs\n",
    "import nibabel as nib\n",
    "from neuromaps.datasets import fetch_annotation, fetch_fslr\n",
    "from enigmatoolbox.datasets import load_sc, load_fc\n",
    "from nilearn.image import resample_to_img\n",
    "\n",
    "# Set seed to 127\n",
    "random.seed(127)\n",
    "\n",
    "# Add connectome workbench to path\n",
    "os.environ['PATH'] = os.environ['PATH'] + ':/Applications/workbench/bin_macosx64'\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "suppressPackageStartupMessages({\n",
    "    library(broom)\n",
    "    library(cowplot)\n",
    "    library(ggseg)\n",
    "    library(glue)\n",
    "    library(grid)\n",
    "    library(patchwork)\n",
    "    library(see)\n",
    "    library(tidyverse)\n",
    "})\n",
    "\n",
    "# Set cowplot theme\n",
    "theme_set(theme_cowplot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the data and filter to Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/abry4213/data/HCP100/\"\n",
    "github_data_path = \"/Users/abry4213/github/Homotopic_FC/data/\"\n",
    "\n",
    "#### GROUP-AVERAGED FUNCTIONAL CONNECTOME FROM ENIGMA #### \n",
    "# Load cortico-cortical functional connectivity data\n",
    "fc_ctx, fc_ctx_labels, _, _ = load_fc(parcellation='aparc')\n",
    "\n",
    "# Read in preprocessed Pearson-based functional connectivity data from ENIGMA\n",
    "HCP_avg_Pearson_FC = (pd.DataFrame(fc_ctx, columns=fc_ctx_labels)\n",
    "                      .assign(Brain_Region_From = fc_ctx_labels)\n",
    "                      .melt(id_vars=[\"Brain_Region_From\"], \n",
    "                             var_name=\"Brain_Region_To\", \n",
    "                             value_name=\"Mean_Pearson_R\")\n",
    "                      .assign(Base_Region_From = lambda x: x['Brain_Region_From'].str.replace(\"L_\", \"\").str.replace(\"R_\", \"\"),\n",
    "                              Base_Region_To = lambda x: x['Brain_Region_To'].str.replace(\"L_\", \"\").str.replace(\"R_\", \"\"),\n",
    "                              Hemi_From = lambda x: np.where(x['Brain_Region_From'].str.startswith(\"L_\"), \"Left\", \"Right\"),\n",
    "                              Hemi_To = lambda x: np.where(x['Brain_Region_To'].str.startswith(\"L_\"), \"Left\", \"Right\"))\n",
    ")\n",
    "pearson_homotopic_res_mean = (HCP_avg_Pearson_FC\n",
    "                              .query(\"Base_Region_From == Base_Region_To\")\n",
    "                              .groupby([\"Base_Region_From\"])['Mean_Pearson_R']\n",
    "                              .mean() \n",
    "                              .reset_index()\n",
    "                              .rename(columns={\"Base_Region_From\": \"Base_Region\"})\n",
    "                              )\n",
    "\n",
    "sc_ctx, sc_ctx_labels, _, _ = load_sc(parcellation='aparc')\n",
    "\n",
    "HCP_avg_Pearson_SC = (pd.DataFrame(sc_ctx, columns=sc_ctx_labels)\n",
    "                      .assign(Brain_Region_From = sc_ctx_labels)\n",
    "                      .melt(id_vars=[\"Brain_Region_From\"], \n",
    "                             var_name=\"Brain_Region_To\", \n",
    "                             value_name=\"Mean_Num_Streamlines\")\n",
    "                      .assign(Base_Region_From = lambda x: x['Brain_Region_From'].str.replace(\"L_\", \"\").str.replace(\"R_\", \"\"),\n",
    "                              Base_Region_To = lambda x: x['Brain_Region_To'].str.replace(\"L_\", \"\").str.replace(\"R_\", \"\"),\n",
    "                              Hemi_From = lambda x: np.where(x['Brain_Region_From'].str.startswith(\"L_\"), \"Left\", \"Right\"),\n",
    "                              Hemi_To = lambda x: np.where(x['Brain_Region_To'].str.startswith(\"L_\"), \"Left\", \"Right\"))\n",
    ")\n",
    "\n",
    "SC_homotopic_res_mean = (HCP_avg_Pearson_SC\n",
    "                            .query(\"Base_Region_From == Base_Region_To\")\n",
    "                            .groupby([\"Base_Region_From\"])['Mean_Num_Streamlines']\n",
    "                            .mean() \n",
    "                            .reset_index()\n",
    "                            .rename(columns={\"Base_Region_From\": \"Base_Region\"})\n",
    "                            .rename(columns={\"Mean_Num_Streamlines\": \"Value\"})\n",
    "                            .assign(Category = \"Microstructure\", Description = \"Log-SC\")\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining with `by = join_by(label)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i pearson_homotopic_res_mean\n",
    "\n",
    "### Pearson FC in brain ###\n",
    "pearson_homotopic_res_mean %>%\n",
    "  ungroup() %>%\n",
    "  mutate(label = glue(\"lh_{Base_Region}\")) %>%\n",
    "  left_join(., as_tibble(dk)) %>%\n",
    "  ggseg(atlas = dk, mapping = aes(fill = Mean_Pearson_R),\n",
    "        position = \"stacked\", colour = \"black\", hemisphere=\"left\",\n",
    "        linewidth=0.5) +\n",
    "  theme_void() +\n",
    "  labs(fill = \"Mean Pearson R\") +\n",
    "      theme(plot.title = element_blank(),\n",
    "            legend.key.width  = unit(3, \"lines\"),\n",
    "            legend.key.height  = unit(0.75, \"lines\"),\n",
    "            legend.position = \"bottom\") +\n",
    "            guides(fill = guide_colorbar(title.position=\"top\", title.hjust=0.5)) +\n",
    "    scale_fill_gradient(low='white', high='#A469E6', na.value='white')\n",
    "ggsave(\"../plots/measure_maps/Mean_LR_averaged_Pearson_R_ggseg.svg\", width = 4, height = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the magnitude of homotopic Pearson FC across brain regions tied to (1) Euclidean distance between the two regions and/or (2) the number of streamlines between those two regions on average?\n",
    "\n",
    "### Calculate Euclidean, geodesic, and fiber connectivity distances between each region--region pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in brain region lookup table\n",
    "brain_region_info = pd.read_csv(\"../data/Brain_Region_Info.csv\")\n",
    "fsaverage_data_base_path = \"/Users/abry4213/data/neuroimaging_atlases/surfaces/DesikanKilliany/fsaverage\"\n",
    "\n",
    "all_centroid_res_list = []\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "\n",
    "    # Load annotation file (parcellation)\n",
    "    annot_path = f\"{fsaverage_data_base_path}/{hemi}.aparc.annot\"\n",
    "    labels, ctab, names = fs.read_annot(annot_path)\n",
    "\n",
    "    # Load label file (vertex coordinates)\n",
    "    label_path = f\"{fsaverage_data_base_path}/{hemi}.aparc.label\"\n",
    "    vertices = fs.read_label(label_path)\n",
    "\n",
    "    # Load the FreeSurfer surface (to get vertex coordinates)\n",
    "    pial_path = f\"{fsaverage_data_base_path}/{hemi}.pial\"\n",
    "    surf = fs.read_geometry(pial_path)\n",
    "    coords, faces = surf\n",
    "    cort = np.sort(fs.read_label(f\"{fsaverage_data_base_path}/{hemi}.cortex.label\"))\n",
    "\n",
    "    # Create a dictionary to store centroids\n",
    "    roi_centroids = {}\n",
    "\n",
    "    # Compute centroids for each ROI\n",
    "    for i, roi_name in enumerate(names):\n",
    "        roi_vertices = np.where(labels == i)[0]  # Get vertex indices in this ROI\n",
    "        if len(roi_vertices) > 0:\n",
    "            roi_centroids[roi_name] = coords[roi_vertices].mean(axis=0)  # Mean position\n",
    "\n",
    "    # Convert centroids to DataFrame\n",
    "    centroid_df = pd.DataFrame(roi_centroids).T\n",
    "    centroid_df.columns = [\"x\", \"y\", \"z\"]\n",
    "\n",
    "    # Convert names to strings, dropping corpuscallosum\n",
    "    names_dec = [name.decode() for name in names if name.decode() not in [\"corpuscallosum\"]]\n",
    "\n",
    "    # If centroid_df has 34 rows, drop 'unknown' from names\n",
    "    if centroid_df.shape[0] == 34:\n",
    "        names_dec = [name for name in names_dec if name != \"unknown\"]\n",
    "\n",
    "    # Add region names and hemisphere\n",
    "    centroid_df = (centroid_df.reset_index(drop=True).assign(Base_Region=names_dec, \n",
    "                                                             Hemisphere=np.where(hemi == \"lh\", \"Left\", \"Right\"))\n",
    "                                                     .assign(Brain_Region = lambda x: hemi + '-' + x['Base_Region']))\n",
    "\n",
    "    # Append to list\n",
    "    all_centroid_res_list.append(centroid_df)\n",
    "\n",
    "# Concatenate the results\n",
    "all_centroid_res = pd.concat(all_centroid_res_list).query(\"Base_Region != 'unknown'\")\n",
    "\n",
    "# Compute Euclidean distances between all ROI centroids\n",
    "dist_matrix = cdist(all_centroid_res[['x', 'y', 'z']], all_centroid_res[['x', 'y', 'z']], metric=\"euclidean\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "euclidean_dist_df = (pd.DataFrame(dist_matrix, index=all_centroid_res['Brain_Region'], \n",
    "                        columns=all_centroid_res['Brain_Region'])\n",
    "                        .reset_index()\n",
    "                        .rename(columns={\"Brain_Region\": \"Brain_Region_From\"})\n",
    "                        .melt(id_vars='Brain_Region_From', var_name='Brain_Region_To', value_name='Euclidean_Distance')\n",
    "                        .query(\"Brain_Region_From != Brain_Region_To\")\n",
    "                        .assign(Base_Region_From = lambda x: x['Brain_Region_From'].str.split('-').str[1],\n",
    "                                Base_Region_To = lambda x: x['Brain_Region_To'].str.split('-').str[1],\n",
    "                                Hemi_From = lambda x: np.where(x['Brain_Region_From'].str.split('-').str[0]=='lh', 'Left', 'Right'),\n",
    "                                Hemi_To = lambda x: np.where(x['Brain_Region_To'].str.split('-').str[0]=='lh', 'Left', 'Right'))\n",
    "                        )\n",
    "\n",
    "# Filter to just the homotopic regions\n",
    "homotopic_euclidean_dist_df = (euclidean_dist_df.query(\"Base_Region_From == Base_Region_To\").drop_duplicates(subset=['Base_Region_To', 'Euclidean_Distance'])\n",
    "                               .filter(['Base_Region_To', 'Euclidean_Distance'])\n",
    "                               .rename(columns={\"Base_Region_To\": \"Base_Region\",\n",
    "                                                \"Euclidean_Distance\": \"Value\"})\n",
    "                               .assign(Category = \"Microstructure\", Description = \"Euclidean Distance\")\n",
    "                               )\n",
    "\n",
    "# Merge the results\n",
    "structural_data = (pd.concat([homotopic_euclidean_dist_df, SC_homotopic_res_mean])\n",
    "                           .merge(pearson_homotopic_res_mean, on=\"Base_Region\", how=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`geom_smooth()` using formula = 'y ~ x'\n",
      "`geom_smooth()` using formula = 'y ~ x'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "In addition: Warning messages:\n",
       "1: The following aesthetics were dropped during statistical transformation: fill.\n",
       "ℹ This can happen when ggplot fails to infer the correct grouping structure in\n",
       "  the data.\n",
       "ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n",
       "  variable into a factor? \n",
       "2: The following aesthetics were dropped during statistical transformation: fill.\n",
       "ℹ This can happen when ggplot fails to infer the correct grouping structure in\n",
       "  the data.\n",
       "ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n",
       "  variable into a factor? \n",
       "3: The following aesthetics were dropped during statistical transformation: fill.\n",
       "ℹ This can happen when ggplot fails to infer the correct grouping structure in\n",
       "  the data.\n",
       "ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n",
       "  variable into a factor? \n",
       "4: The following aesthetics were dropped during statistical transformation: fill.\n",
       "ℹ This can happen when ggplot fails to infer the correct grouping structure in\n",
       "  the data.\n",
       "ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n",
       "  variable into a factor? \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i structural_data\n",
    "\n",
    "colormap <- setNames(c(\"#5c9335\", \"#10b8e8\"), c('Euclidean Distance', 'Log-SC'))\n",
    "\n",
    "all_scatter_plots_list <- list()\n",
    "\n",
    "for (desc in unique(structural_data$Description)) {\n",
    "      desc_color <- colormap[desc]\n",
    "\n",
    "      desc_p_scatter <- structural_data %>% \n",
    "        filter(Description == desc) %>%\n",
    "        ggplot(aes(x=Value, y=Mean_Pearson_R, fill=Value)) +\n",
    "        geom_point(color='black', shape=21, size=3) +\n",
    "        scale_fill_gradient(low=\"white\", high=desc_color, na.value=\"white\") +\n",
    "        geom_smooth(method=\"lm\", se=FALSE, color='black') +\n",
    "        ggtitle(desc) +\n",
    "        theme(legend.position=\"none\") +\n",
    "        ggpubr::stat_cor(method=\"spearman\", cor.coef.name=\"rho\", size=5, aes(label = ..r.label..)) +\n",
    "        xlab(\"Value\") +\n",
    "        ylab(\"Mean Pearson R\") +\n",
    "        theme(strip.background = element_blank(),\n",
    "            plot.title = element_text(hjust=0.5, face='bold', size=16),\n",
    "            strip.text = element_text(face='bold', size=14))\n",
    "\n",
    "      all_scatter_plots_list[[desc]] <- desc_p_scatter\n",
    "}\n",
    "\n",
    "wrap_plots(all_scatter_plots_list, ncol=1)\n",
    "\n",
    "ggsave(\"../plots/measure_maps/Mean_Pearson_R_magnitude_vs_physical_distance.svg\", width=2.7, height=5.25, dpi=300, units=\"in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the SC/Euclidean distance per region in the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining with `by = join_by(label)`\n",
      "Joining with `by = join_by(label)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i structural_data\n",
    "\n",
    "all_ggseg_plots_list <- list()\n",
    "\n",
    "colormap <- setNames(c(\"#5c9335\", \"#10b8e8\"), c('Euclidean Distance', 'Log-SC'))\n",
    "\n",
    "for (desc in unique(structural_data$Description)) {\n",
    "      desc_color <- colormap[desc]\n",
    "\n",
    "      desc_p <- structural_data %>%\n",
    "            filter(Description==desc) %>% \n",
    "            mutate(label = glue(\"lh_{Base_Region}\")) %>%\n",
    "            left_join(., as_tibble(dk)) %>%\n",
    "            ggseg(atlas = dk, mapping = aes(fill = Value),\n",
    "                  position = \"stacked\", colour = \"black\", hemisphere=\"left\",\n",
    "                  linewidth=0.5) +\n",
    "            theme_void() +\n",
    "            labs(fill = desc) +\n",
    "            scale_fill_gradient(low=\"white\", high=desc_color, na.value=\"white\")+\n",
    "            theme(plot.title = element_blank(),\n",
    "            legend.key.width  = unit(3, \"lines\"),\n",
    "            legend.key.height  = unit(0.75, \"lines\"),\n",
    "            legend.position = \"bottom\") +\n",
    "            guides(fill = guide_colorbar(title.position=\"top\", title.hjust=0.5))\n",
    "\n",
    "      all_ggseg_plots_list[[desc]] <- desc_p\n",
    "}\n",
    "\n",
    "wrap_plots(all_ggseg_plots_list, ncol=1)\n",
    "ggsave(\"../plots/measure_maps/structural_data_ggseg_res.svg\", width=4, height=4, dpi=300, units=\"in\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is mean homotopic FC correlated with region volume?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=np.float64(0.0985485103132162), pvalue=np.float64(0.5792431104724365))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in regional volumes\n",
    "regional_volumes = pd.read_csv(f\"{data_path}/raw_data/structural_MRI/HCP100_all_dk_volumes.csv\")\n",
    "regional_volumes_mean = (regional_volumes\n",
    "                         .groupby('Region')['Volume']\n",
    "                         .agg(['mean', 'std'])\n",
    "                         .reset_index()\n",
    "                         .rename(columns={\"Region\": \"Region_Index\", \"mean\": \"Mean_Volume\", \"std\": \"SD_Volume\"})\n",
    "                         .assign(Region_Index = lambda x: x.Region_Index.astype(int))\n",
    "                         .merge(brain_region_info, on=\"Region_Index\", how=\"left\")\n",
    ")\n",
    "\n",
    "regional_volumes_mean_hemi_avg = (regional_volumes\n",
    "    .rename(columns={\"Region\": \"Region_Index\"})\n",
    "    .merge(brain_region_info, on=\"Region_Index\", how=\"left\")\n",
    "    .groupby('Base_Region')['Volume']\n",
    "    .agg(['mean', 'std'])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"mean\": \"Mean_Volume\", \"std\": \"SD_Volume\"})\n",
    "    .merge(pearson_homotopic_res_mean, on=\"Base_Region\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Fit a Spearman correlation\n",
    "volume_pearson_corr = spearmanr(regional_volumes_mean_hemi_avg['Mean_Volume'], regional_volumes_mean_hemi_avg['Mean_Pearson_R'])\n",
    "volume_pearson_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`geom_smooth()` using formula = 'y ~ x'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "In addition: Warning messages:\n",
       "1: The following aesthetics were dropped during statistical transformation: fill.\n",
       "ℹ This can happen when ggplot fails to infer the correct grouping structure in\n",
       "  the data.\n",
       "ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n",
       "  variable into a factor? \n",
       "2: The following aesthetics were dropped during statistical transformation: fill.\n",
       "ℹ This can happen when ggplot fails to infer the correct grouping structure in\n",
       "  the data.\n",
       "ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n",
       "  variable into a factor? \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i regional_volumes_mean_hemi_avg\n",
    "\n",
    "regional_volumes_mean_hemi_avg %>%\n",
    "    ggplot(aes(x=Mean_Volume, y=Mean_Pearson_R, fill=Mean_Volume)) +\n",
    "    geom_point(color='black', shape=21, size=4) +\n",
    "      scale_fill_gradient(low=\"white\", high=\"#F1D201\", na.value=\"white\")+\n",
    "    geom_smooth(method=\"lm\", se=FALSE, color='black') +\n",
    "    ggpubr::stat_cor(method=\"spearman\", cor.coef.name=\"rho\", size=5, aes(label = ..r.label..)) +\n",
    "    xlab(\"Mean Volume\") +\n",
    "    ylab(\"Mean Pearson R\") +\n",
    "    theme(legend.position=\"none\",\n",
    "          axis.text = element_text(size=16),\n",
    "          axis.title = element_text(size=16))\n",
    "ggsave(\"../plots/measure_maps/Mean_Pearson_R_magnitude_vs_volume.svg\", width=3.5, height=3.2, dpi=300, units=\"in\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining with `by = join_by(label)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i regional_volumes_mean_hemi_avg\n",
    "\n",
    "regional_volumes_mean_hemi_avg %>%\n",
    "      mutate(label = glue(\"lh_{Base_Region}\")) %>%\n",
    "      left_join(., as_tibble(dk)) %>%\n",
    "      ggseg(atlas = dk, mapping = aes(fill = Mean_Volume),\n",
    "            position = \"stacked\", colour = \"black\", hemisphere=\"left\",\n",
    "            linewidth=0.5) +\n",
    "      theme_void() +\n",
    "      labs(fill = \"Mean volume\") +\n",
    "      scale_fill_gradient(low=\"white\", high=\"#F1D201\", na.value=\"white\")+\n",
    "      theme(plot.title = element_blank(),\n",
    "            legend.key.width  = unit(3, \"lines\"),\n",
    "            legend.key.height  = unit(0.75, \"lines\"),\n",
    "            legend.position = \"bottom\") +\n",
    "      guides(fill = guide_colorbar(title.position=\"top\", title.hjust=0.5))\n",
    "\n",
    "ggsave(\"../plots/measure_maps/Mean_Pearson_R_magnitude_vs_volume_ggseg.svg\", width=4, height=2, dpi=300, units=\"in\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associations with vascular density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(f\"{github_data_path}/Arterial_Venous_Mean_Density_aparc.csv\"):\n",
    "\n",
    "    # aparc + aseg volume\n",
    "    ROI_image = nib.load(\"/Users/abry4213/data/neuroimaging_atlases/volumes/freesurfer_segmentations/mni152_space/atlas-desikankilliany.nii.gz\")\n",
    "    ROI_lookup = pd.read_csv(\"/Users/abry4213/data/neuroimaging_atlases/volumes/freesurfer_segmentations/mni152_space/atlas-desikankilliany.csv\")\n",
    "\n",
    "    # Read in vasculature volumes (arterial and venous)\n",
    "    arterial_image = nib.load(f\"{github_data_path}/vasculature/mean_Ved_ToF_filt.nii.gz\")\n",
    "    venous_image = nib.load(f\"{github_data_path}/vasculature/mean_Ved_swi_filt.nii.gz\")\n",
    "\n",
    "    # Downsample the segmentation volume to match the vasculature images\n",
    "    ROI_image_resampled = resample_to_img(ROI_image, arterial_image, interpolation='nearest')\n",
    "    ROI_data_resampled = ROI_image_resampled.get_fdata().flatten()\n",
    "\n",
    "    # Extract data arrays\n",
    "    venous_data = venous_image.get_fdata().flatten()\n",
    "    arterial_data = arterial_image.get_fdata().flatten()\n",
    "\n",
    "    ROI_indices = [int(i) for i in np.unique(ROI_data_resampled) if i != 0]\n",
    "\n",
    "    regional_vascular_data_list = [] \n",
    "\n",
    "    for this_index in ROI_indices:\n",
    "        region_info = ROI_lookup.query(\"id == @this_index\")[['id', 'label', 'hemisphere']]\n",
    "\n",
    "        arterial_roi_data = np.mean(arterial_data[ROI_data_resampled == this_index])\n",
    "        venous_roi_data = np.mean(venous_data[ROI_data_resampled == this_index])\n",
    "\n",
    "        ROI_vascular_df = pd.DataFrame({\"id\": this_index,\n",
    "                                        \"Arterial_Vascular\": arterial_roi_data,\n",
    "                                        \"Venous_Vascular\": venous_roi_data}, index=[0]).merge(region_info, on='id', how='left')\n",
    "        \n",
    "        regional_vascular_data_list.append(ROI_vascular_df)\n",
    "\n",
    "    regional_vascular_data = (pd.concat(regional_vascular_data_list, ignore_index=True)\n",
    "                            .rename(columns={\"label\": \"Base_Region\",\n",
    "                                            'hemisphere': \"Hemisphere\"})\n",
    "    )\n",
    "\n",
    "    # Save to CSV\n",
    "    regional_vascular_data.to_csv(f\"{github_data_path}/Arterial_Venous_Mean_Density_aparc.csv\", index=False)\n",
    "\n",
    "else: \n",
    "    regional_vascular_data = pd.read_csv(f\"{github_data_path}/Arterial_Venous_Mean_Density_aparc.csv\")\n",
    "\n",
    "# Take the mean of left/right\n",
    "regional_vascular_data = regional_vascular_data.groupby(['Base_Region'])[['Arterial_Vascular', 'Venous_Vascular']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining with `by = join_by(label)`\n",
      "Joining with `by = join_by(label)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "In addition: Warning messages:\n",
       "1: Some data not merged properly. Check for naming errors in data:\n",
       "  atlas type  hemi  side  region label       roi   Base_Region Arterial_Vascular\n",
       "  <chr> <chr> <chr> <chr> <chr>  <glue>      <chr> <chr>                   <dbl>\n",
       "1 <NA>  <NA>  <NA>  <NA>  <NA>   lh_accumbe… <NA>  accumbensa…              41.7\n",
       "2 <NA>  <NA>  <NA>  <NA>  <NA>   lh_amygdala <NA>  amygdala                 22.4\n",
       "3 <NA>  <NA>  <NA>  <NA>  <NA>   lh_brainst… <NA>  brainstem                46.9\n",
       "4 <NA>  <NA>  <NA>  <NA>  <NA>   lh_caudate  <NA>  caudate                  14.9\n",
       "5 <NA>  <NA>  <NA>  <NA>  <NA>   lh_hippoca… <NA>  hippocampus              21.0\n",
       "6 <NA>  <NA>  <NA>  <NA>  <NA>   lh_pallidum <NA>  pallidum                 13.4\n",
       "7 <NA>  <NA>  <NA>  <NA>  <NA>   lh_putamen  <NA>  putamen                  18.4\n",
       "8 <NA>  <NA>  <NA>  <NA>  <NA>   lh_thalamu… <NA>  thalamuspr…              17.4\n",
       "# ℹ 2 more variables: Venous_Vascular <dbl>, geometry <MULTIPOLYGON> \n",
       "2: Some data not merged properly. Check for naming errors in data:\n",
       "  atlas type  hemi  side  region label       roi   Base_Region Arterial_Vascular\n",
       "  <chr> <chr> <chr> <chr> <chr>  <glue>      <chr> <chr>                   <dbl>\n",
       "1 <NA>  <NA>  <NA>  <NA>  <NA>   lh_accumbe… <NA>  accumbensa…              41.7\n",
       "2 <NA>  <NA>  <NA>  <NA>  <NA>   lh_amygdala <NA>  amygdala                 22.4\n",
       "3 <NA>  <NA>  <NA>  <NA>  <NA>   lh_brainst… <NA>  brainstem                46.9\n",
       "4 <NA>  <NA>  <NA>  <NA>  <NA>   lh_caudate  <NA>  caudate                  14.9\n",
       "5 <NA>  <NA>  <NA>  <NA>  <NA>   lh_hippoca… <NA>  hippocampus              21.0\n",
       "6 <NA>  <NA>  <NA>  <NA>  <NA>   lh_pallidum <NA>  pallidum                 13.4\n",
       "7 <NA>  <NA>  <NA>  <NA>  <NA>   lh_putamen  <NA>  putamen                  18.4\n",
       "8 <NA>  <NA>  <NA>  <NA>  <NA>   lh_thalamu… <NA>  thalamuspr…              17.4\n",
       "# ℹ 2 more variables: Venous_Vascular <dbl>, geometry <MULTIPOLYGON> \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i regional_vascular_data\n",
    "\n",
    "### Arterial density brain ###\n",
    "regional_vascular_data %>%\n",
    "  ungroup() %>%\n",
    "  mutate(label = glue(\"lh_{Base_Region}\")) %>%\n",
    "  left_join(., as_tibble(dk)) %>%\n",
    "  ggseg(atlas = dk, mapping = aes(fill = Arterial_Vascular),\n",
    "        position = \"stacked\", colour = \"black\", hemisphere=\"left\",\n",
    "        linewidth=0.5) +\n",
    "  theme_void() +\n",
    "  labs(fill = \"Mean arterial density\") +\n",
    "  scale_fill_gradient(low = \"white\", high = \"#e24528\", na.value=\"white\") +\n",
    "  theme(plot.title = element_blank(),\n",
    "        legend.key.width  = unit(3, \"lines\"),\n",
    "        legend.key.height  = unit(0.75, \"lines\"),\n",
    "        legend.position = \"bottom\") +\n",
    "  guides(fill = guide_colorbar(title.position=\"top\", title.hjust=0.5))\n",
    "\n",
    "# ggsave(\"../plots/measure_maps/Arterial_density_cortex.svg\", width=5, height=3, units='in', dpi=300)\n",
    "\n",
    "\n",
    "### Venous density in brain ###\n",
    "regional_vascular_data %>%\n",
    "  ungroup() %>%\n",
    "  mutate(label = glue(\"lh_{Base_Region}\")) %>%\n",
    "  left_join(., as_tibble(dk)) %>%\n",
    "  ggseg(atlas = dk, mapping = aes(fill = Venous_Vascular),\n",
    "        position = \"stacked\", colour = \"black\", hemisphere=\"left\",\n",
    "        linewidth=0.5) +\n",
    "  theme_void() +\n",
    "  labs(fill = \"Mean venous density\") +\n",
    "  scale_fill_gradient(low = \"white\", high = \"#d41d56\", na.value=\"white\") +\n",
    "  theme(plot.title = element_blank(),\n",
    "        legend.key.width  = unit(3, \"lines\"),\n",
    "        legend.key.height  = unit(0.75, \"lines\"),\n",
    "        legend.position = \"bottom\") +\n",
    "  guides(fill = guide_colorbar(title.position=\"top\", title.hjust=0.5))\n",
    "\n",
    "# ggsave(\"../plots/measure_maps/Venous_density_cortex.svg\", width=5, height=3, units='in', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is homotopic connectivity correlated with vascular innervation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base_Region</th>\n",
       "      <th>Mean_Pearson_R</th>\n",
       "      <th>Arterial_Vascular</th>\n",
       "      <th>Venous_Vascular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bankssts</td>\n",
       "      <td>0.314670</td>\n",
       "      <td>5.629985</td>\n",
       "      <td>39.885609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caudalanteriorcingulate</td>\n",
       "      <td>0.213912</td>\n",
       "      <td>20.057773</td>\n",
       "      <td>38.279240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>caudalmiddlefrontal</td>\n",
       "      <td>0.330858</td>\n",
       "      <td>17.089778</td>\n",
       "      <td>32.134382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cuneus</td>\n",
       "      <td>0.644840</td>\n",
       "      <td>15.818715</td>\n",
       "      <td>69.034659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entorhinal</td>\n",
       "      <td>0.029524</td>\n",
       "      <td>27.140752</td>\n",
       "      <td>80.060211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Base_Region  Mean_Pearson_R  Arterial_Vascular  Venous_Vascular\n",
       "0                 bankssts        0.314670           5.629985        39.885609\n",
       "1  caudalanteriorcingulate        0.213912          20.057773        38.279240\n",
       "2      caudalmiddlefrontal        0.330858          17.089778        32.134382\n",
       "3                   cuneus        0.644840          15.818715        69.034659\n",
       "4               entorhinal        0.029524          27.140752        80.060211"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HoFC_and_vascular_info = pd.merge(pearson_homotopic_res_mean, regional_vascular_data, on='Base_Region', how='left')\n",
    "\n",
    "HoFC_and_vascular_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`geom_smooth()` using formula = 'y ~ x'\n",
      "`geom_smooth()` using formula = 'y ~ x'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "In addition: Warning messages:\n",
       "1: The following aesthetics were dropped during statistical transformation: fill.\n",
       "ℹ This can happen when ggplot fails to infer the correct grouping structure in\n",
       "  the data.\n",
       "ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n",
       "  variable into a factor? \n",
       "2: The following aesthetics were dropped during statistical transformation: fill.\n",
       "ℹ This can happen when ggplot fails to infer the correct grouping structure in\n",
       "  the data.\n",
       "ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n",
       "  variable into a factor? \n",
       "3: The following aesthetics were dropped during statistical transformation: fill.\n",
       "ℹ This can happen when ggplot fails to infer the correct grouping structure in\n",
       "  the data.\n",
       "ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n",
       "  variable into a factor? \n",
       "4: The following aesthetics were dropped during statistical transformation: fill.\n",
       "ℹ This can happen when ggplot fails to infer the correct grouping structure in\n",
       "  the data.\n",
       "ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n",
       "  variable into a factor? \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i HoFC_and_vascular_info -w 800 -h 400\n",
    "\n",
    "arterial_scatter_plot <- HoFC_and_vascular_info %>% \n",
    "    ggplot(data=., mapping=aes(x=Arterial_Vascular, y=Mean_Pearson_R, fill=Arterial_Vascular)) +\n",
    "    geom_point(color='black', shape=21, size=3) +\n",
    "    scale_fill_gradient(low = \"white\", high = \"#e24528\", na.value=\"white\") +\n",
    "    geom_smooth(method=\"lm\", se=FALSE, color='black') +\n",
    "    ggpubr::stat_cor(method=\"spearman\", cor.coef.name=\"rho\", size=5, aes(label = ..r.label..)) +\n",
    "    xlab(\"Mean Arterial Density\") +\n",
    "    ylab(\"Mean Pearson R\") +\n",
    "    theme(legend.position=\"none\",\n",
    "          strip.background = element_blank(),\n",
    "          strip.text = element_text(face='bold', size=14))\n",
    "\n",
    "venous_scatter_plot <- HoFC_and_vascular_info %>% \n",
    "    ggplot(data=., mapping=aes(x=Venous_Vascular, y=Mean_Pearson_R, fill=Venous_Vascular)) +\n",
    "    geom_point(color='black', shape=21, size=3) +\n",
    "    scale_fill_gradient(low = \"white\", high = \"#d41d56\", na.value=\"white\") +\n",
    "    geom_smooth(method=\"lm\", se=FALSE, color='black') +\n",
    "    ggpubr::stat_cor(method=\"spearman\", cor.coef.name=\"rho\", size=5, aes(label = ..r.label..)) +\n",
    "    xlab(\"Mean Arterial Density\") +\n",
    "    ylab(\"Mean Pearson R\") +\n",
    "    theme(legend.position=\"none\",\n",
    "          strip.background = element_blank(),\n",
    "          strip.text = element_text(face='bold', size=14))\n",
    "\n",
    "wrap_plots(list(arterial_scatter_plot, venous_scatter_plot), ncol=1)\n",
    "\n",
    "ggsave(\"../plots/measure_maps/Mean_Pearson_R_magnitude_vs_vascular_density_scatter.svg\", width=2.7, height=5, dpi=300, units=\"in\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annie_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
