{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules and read in data\n",
    "\n",
    "First, we will import all the modules needed for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspi.calculator import Calculator\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Define data directory\n",
    "data_dir = \"data/numpy_arrays/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with pyspi\n",
    "\n",
    "Let's go through some of the basics with `pyspi` functionality to warm up. The core object in `pyspi` is a `Calculator`, which stores your input multivariate time series (MTS) data, configuration parameters, and ultimately the computed metrics -- called \"statistics of pairwise interactions\", or \"SPIs\" for short.\n",
    "\n",
    "By default, when you initialise a `Calculator` object, it loads in all 283 available SPIs, which range from basic statistics like the Pearson correlation coefficient to frequency-based metrics like the spectral Granger causality. In this project, we will focus on just one SPI: directed information with a Gaussian density estimator, which is denoted as `di_gaussian` within `pyspi`. To save time and computational power, instead of computing all 283 SPIs, we can load our `Calculator` object with a `YAML` configuration file that only specifies the `di_gaussian` metric: `DI_Gaussian_config.yaml`, contained in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration file: DI_Gaussian_config.yaml\n",
      "*** Importing module .statistics.infotheory\n",
      "[0] Adding SPI .statistics.infotheory.DirectedInfo(x,y,{'estimator': 'gaussian'})...\n",
      "Succesfully initialised SPI with identifier \"di_gaussian\" and labels ['unsigned', 'infotheory', 'temporal', 'directed', 'linear']\n",
      "Number of SPIs: 1\n"
     ]
    }
   ],
   "source": [
    "# Define configuration file\n",
    "di_gaussian_config_file = \"DI_Gaussian_config.yaml\"\n",
    "\n",
    "# Initialise a Calculator object with this configuration file\n",
    "calc = Calculator(configfile=di_gaussian_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created our Calculator object, we can load in an MTS matrix in the form of a 2D `NumPy` array. For now, we can simulate some random data to demonstrate how this process works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Create a random dataset consisting of 3 processes and 100 time points\n",
    "example_data = np.random.randn(3,100)\n",
    "\n",
    "# Load example_data into the Calculator object\n",
    "calc.load_dataset(example_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run compute our SPI of interest, `di_gaussian`, all we need to do is call the `compute()` method on our `calc` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing [None: di_gaussian]: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>spi</th>\n",
       "      <th colspan=\"3\" halign=\"left\">di_gaussian</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <th>proc-0</th>\n",
       "      <th>proc-1</th>\n",
       "      <th>proc-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>proc-0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083606</td>\n",
       "      <td>0.071625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proc-1</th>\n",
       "      <td>0.100800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.085793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proc-2</th>\n",
       "      <td>0.118297</td>\n",
       "      <td>0.044851</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "spi     di_gaussian                    \n",
       "process      proc-0    proc-1    proc-2\n",
       "proc-0          NaN  0.083606  0.071625\n",
       "proc-1     0.100800       NaN  0.085793\n",
       "proc-2     0.118297  0.044851       NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the SPI (di_gaussian) defined in the Calculator object\n",
    "calc.compute()\n",
    "\n",
    "# Our results are stored in the calc.table object:\n",
    "calc.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this `DataFrame` we can see that the SPI is `di_gaussian` and we now have a 3x3 `NumPy` array containing the SPI values for each pair of processes (which in our case, will represent brain regions). There are two key things to note:\n",
    "1. The diagonal of the matrix contains all `NaN`, because these represent self-connections and therefore are not valid for pairwise interaction analysis; and \n",
    "2. The matrix is not symmetrical -- meaning that the statistics are not the same going from proc-0 to proc-1 as the other way around. This is because `di_gaussian` is a **directed** statistic, meaning that it is sensitive to the flow of information from one time series to the other.\n",
    "\n",
    "If we want to loop over a few `DataFrames` and compute the `di_gaussian` for each pair of time-series per `DataFrame`, here's how we could do that with a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_gaussian_list = []\n",
    "\n",
    "# For five loops, create a random dataset and compute the DI\n",
    "for i in range(5):\n",
    "    # Create a random dataset consisting of 3 processes and 100 time points\n",
    "    example_data = np.random.randn(3,100)\n",
    "\n",
    "    # Create a Calculator object\n",
    "    calc = Calculator(configfile=di_gaussian_config_file)\n",
    "    \n",
    "    # Load example_data into the Calculator object\n",
    "    calc.load_dataset(example_data)\n",
    "    \n",
    "    # Compute the SPI (di_gaussian) defined in the Calculator object\n",
    "    calc.compute()\n",
    "    \n",
    "    # Extract directed information results as the calc.table object\n",
    "    di_gaussian_loop = calc.table\n",
    "\n",
    "    # Save the loop number as a column\n",
    "    di_gaussian_loop['loop'] = i\n",
    "    \n",
    "    # Append the results to the di_gaussian_list\n",
    "    di_gaussian_list.append(di_gaussian_loop)\n",
    "\n",
    "# Concatenate the list of dataframes into a single dataframe\n",
    "di_gaussian = pd.concat(di_gaussian_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spi     di_gaussian                     loop\n",
      "process      proc-0    proc-1    proc-2     \n",
      "proc-0          NaN  0.051469  0.139332    0\n",
      "proc-1     0.143151       NaN  0.228912    0\n",
      "proc-2     0.075384  0.229729       NaN    0\n",
      "proc-0          NaN  0.080228  0.127084    1\n",
      "proc-1     0.051555       NaN  0.046238    1\n",
      "proc-2     0.054214  0.148641       NaN    1\n",
      "proc-0          NaN  0.044071  0.017890    2\n",
      "proc-1     0.079396       NaN  0.027242    2\n",
      "proc-2     0.091985  0.069918       NaN    2\n",
      "proc-0          NaN  0.193310  0.110272    3\n",
      "proc-1     0.117513       NaN  0.179050    3\n",
      "proc-2     0.127888  0.130539       NaN    3\n",
      "proc-0          NaN  0.163518  0.077114    4\n",
      "proc-1     0.043750       NaN  0.060441    4\n",
      "proc-2     0.031399  0.128487       NaN    4\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(di_gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code chunk collects the `di_gaussian` matrices for each loop into one `DataFrame` for downstream analysis -- we'll use this same approach to iterate over all brain regions per participant in the Human Connectome Project dataset, computing the `di_gaussian` between the left and right hemispheres. \n",
    "\n",
    "Instead of re-initializing a `Calculator` object for every single iteration, we can instead create one base `Calculator` object and then make a copy of it for each iteration using the `deepcopy` function from the `copy` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_gaussian_list = []\n",
    "\n",
    "# Create a base Calculator object\n",
    "basecalc = Calculator(configfile=\"DI_Gaussian_config.yaml\")\n",
    "\n",
    "# For five loops, create a random dataset and compute the DI\n",
    "for i in range(5):\n",
    "    # Create a random dataset consisting of 3 processes and 100 time points\n",
    "    example_data = np.random.randn(3,100)\n",
    "\n",
    "    # Create a deepcopy of the base Calculator object\n",
    "    calc = deepcopy(basecalc)\n",
    "    \n",
    "    # Load example_data into the Calculator object\n",
    "    calc.load_dataset(example_data)\n",
    "    \n",
    "    # Compute the SPI (di_gaussian) defined in the Calculator object\n",
    "    calc.compute()\n",
    "    \n",
    "    # Extract directed information results as the calc.table object\n",
    "    di_gaussian_loop = calc.table\n",
    "\n",
    "    # Save the loop number as a column\n",
    "    di_gaussian_loop['loop'] = i\n",
    "    \n",
    "    # Append the results to the di_gaussian_list\n",
    "    di_gaussian_list.append(di_gaussian_loop)\n",
    "\n",
    "# Concatenate the list of dataframes into a single dataframe\n",
    "di_gaussian = pd.concat(di_gaussian_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spi     di_gaussian                     loop\n",
      "process      proc-0    proc-1    proc-2     \n",
      "proc-0          NaN  0.017166  0.090560    0\n",
      "proc-1     0.017861       NaN  0.224622    0\n",
      "proc-2     0.032620  0.160740       NaN    0\n",
      "proc-0          NaN  0.157732  0.091928    1\n",
      "proc-1     0.035975       NaN  0.090116    1\n",
      "proc-2     0.165681  0.079590       NaN    1\n",
      "proc-0          NaN  0.186787  0.049507    2\n",
      "proc-1     0.077299       NaN  0.202556    2\n",
      "proc-2     0.088986  0.202802       NaN    2\n",
      "proc-0          NaN  0.120454  0.060025    3\n",
      "proc-1     0.006719       NaN  0.025289    3\n",
      "proc-2    -0.011398  0.058133       NaN    3\n",
      "proc-0          NaN  0.072242  0.074851    4\n",
      "proc-1     0.099889       NaN  0.084171    4\n",
      "proc-2     0.079745  0.087110       NaN    4\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(di_gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with real neuroimaging data from the Human Connectome Project\n",
    "\n",
    "For our case study, we will be working with high-quality resting-state functional magnetic resonance imaging (fMRI) data from 100 participants in the Human Connectome Project (HCP100). \n",
    "\n",
    "Voxels in the cortex (gray matter on the brain's surface) can be divided into brain regions in many different ways; in this dataset, each participant's cortex was segmented into 68 regions, comprising 34 unique regions in each hemisphere (right and left). \n",
    "This atlas -- the Desikan-Killiany atlas -- is shown at the top left of the following figure, originally published in [Fürtjes et al. *Cortex* (2023)](https://doi.org/10.1016/j.cortex.2022.11.001):  \n",
    "\n",
    "<img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0010945222003008-gr1.jpg\" width=\"50%\" height=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fMRI data, what we measure is blood oxygen-level dependent (BOLD) signaling that reflects the ratio of oxygenated versus deoxygenated hemoglobin in the blood. This is a proxy readout for neural activity, since increased activity in a brain region will prompt increased blood flow to that region through a pathway called neurovascular coupling.\n",
    "For each voxel, the BOLD signal is measured over 1,200 time points; we then aggregate across all the voxels in a given region to get the average BOLD time series for that region.\n",
    "This means that for each subject in the HCP100 dataset, we have a 68 x 1200 matrix for all brain regions by time points.\n",
    "\n",
    "This fMRI data was already preprocessed as part of [Fallon et al. *Network Neuroscience* (2020)](https://pubmed.ncbi.nlm.nih.gov/33615091/). The code for this paper can be found at [https://github.com/DynamicsAndNeuralSystems/humanStructureFunction](https://github.com/DynamicsAndNeuralSystems/humanStructureFunction) and the data can be downloaded from [Zenodo](https://zenodo.org/record/4643074).\n",
    "\n",
    "For our purposes, we have already parsed each subject's Matlab `.mat` files into individual `NumPy` arrays that are stored in `.npy` files for easy loading into Python.\n",
    "These are included in the [data/numpy_arrays/](https://github.com/DynamicsAndNeuralSystems/Directed_information_fMRI/tree/main/data/numpy_arrays) folder in this repo.\n",
    "\n",
    "Let's load in one of these files with the `np.load()` function (where `np` is an alias for `numpy`) and examine the data structure to know what we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.60778374 -0.98263907 -0.68103114  0.43221171 -0.54265908  0.19205564\n",
      "   0.73322423  0.73347631  1.04091909 -0.26856168  1.09567074  1.64613661\n",
      "   1.28347511 -0.06633166  0.58277635 -1.99615489 -0.4640819  -1.27861954\n",
      "   1.09482733  1.09997448]\n",
      " [-0.166792   -1.9242528  -1.50736902 -0.60595182 -0.3713573   1.45826845\n",
      "  -0.33929535  0.53375432  0.55757112  0.54106949  0.94932919  1.48659255\n",
      "   0.66942609  1.40101728  2.54179148  0.61465474  0.87365191  1.03290417\n",
      "   0.15311191  2.00881693]\n",
      " [-0.81218222 -0.36716754  0.03075874  2.13221635  0.06484777  0.41182043\n",
      "   0.4203798   0.45791618  0.6308759   0.26260445 -0.97917152 -1.16845825\n",
      "  -0.31068965  1.11679565  0.3130997   1.54490938  0.73089731 -0.00552274\n",
      "  -0.3219353  -1.35928571]\n",
      " [ 0.35714679 -0.88998292 -1.25442004 -2.00446651 -1.24282621 -1.77447153\n",
      "  -1.18750537 -1.29986359 -0.40973432 -0.25304476  0.03764887 -0.19349954\n",
      "   0.14567891 -1.22013181 -1.31565385 -0.38236477 -0.19735502  1.32893186\n",
      "   0.69123047 -0.64406845]\n",
      " [ 0.06558218 -0.7452312   1.01096204 -0.23027405  1.31525238  0.93172677\n",
      "  -2.06065874  0.61512883  0.10925237 -0.65785173 -0.65488081  0.48052502\n",
      "   0.39768207 -0.35414431  0.50201538  0.22782194  0.74258313 -1.85426669\n",
      "  -0.65868708 -0.8569267 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load in the numpy array for subject 100307\n",
    "subject = \"100307\"\n",
    "subject_data = np.load(f\"data/numpy_arrays/{subject}.npy\")\n",
    "\n",
    "# Print the first 5 rows and first 20 columns of subject_data\n",
    "print(subject_data[:5, :20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've printed out the first 5 rows (corresponding to the first 5 brain regions) and the first 20 columns (corresponding to the first 20 time points) of the 68-by-1200 array.\n",
    "\n",
    "Note that the array doesn't store the name of any brain region, so we'll need to link this information later.\n",
    "We provide a lookup table to go between row index and region name in [Brain_Region_info.csv](https://github.com/DynamicsAndNeuralSystems/Directed_information_fMRI/blob/main/Brain_Region_info.csv).\n",
    "\n",
    "We can load this lookup table in here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region_Index</th>\n",
       "      <th>Brain_Region</th>\n",
       "      <th>ggseg</th>\n",
       "      <th>Hemisphere</th>\n",
       "      <th>Base_Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ctx-lh-bankssts</td>\n",
       "      <td>ctx-lh-bankssts</td>\n",
       "      <td>Left</td>\n",
       "      <td>bankssts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ctx-lh-caudalanteriorcingulate</td>\n",
       "      <td>ctx-lh-caudalanteriorcingulate</td>\n",
       "      <td>Left</td>\n",
       "      <td>caudalanteriorcingulate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ctx-lh-caudalmiddlefrontal</td>\n",
       "      <td>ctx-lh-caudalmiddlefrontal</td>\n",
       "      <td>Left</td>\n",
       "      <td>caudalmiddlefrontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ctx-lh-cuneus</td>\n",
       "      <td>ctx-lh-cuneus</td>\n",
       "      <td>Left</td>\n",
       "      <td>cuneus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ctx-lh-entorhinal</td>\n",
       "      <td>ctx-lh-entorhinal</td>\n",
       "      <td>Left</td>\n",
       "      <td>entorhinal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>ctx-rh-supramarginal</td>\n",
       "      <td>ctx-rh-supramarginal</td>\n",
       "      <td>Right</td>\n",
       "      <td>supramarginal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>ctx-rh-frontalpole</td>\n",
       "      <td>ctx-rh-frontalpole</td>\n",
       "      <td>Right</td>\n",
       "      <td>frontalpole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>ctx-rh-temporalpole</td>\n",
       "      <td>ctx-rh-temporalpole</td>\n",
       "      <td>Right</td>\n",
       "      <td>temporalpole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>ctx-rh-transversetemporal</td>\n",
       "      <td>ctx-rh-transversetemporal</td>\n",
       "      <td>Right</td>\n",
       "      <td>transversetemporal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>ctx-rh-insula</td>\n",
       "      <td>ctx-rh-insula</td>\n",
       "      <td>Right</td>\n",
       "      <td>insula</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Region_Index                    Brain_Region  \\\n",
       "0              0                 ctx-lh-bankssts   \n",
       "1              1  ctx-lh-caudalanteriorcingulate   \n",
       "2              2      ctx-lh-caudalmiddlefrontal   \n",
       "3              3                   ctx-lh-cuneus   \n",
       "4              4               ctx-lh-entorhinal   \n",
       "..           ...                             ...   \n",
       "63            63            ctx-rh-supramarginal   \n",
       "64            64              ctx-rh-frontalpole   \n",
       "65            65             ctx-rh-temporalpole   \n",
       "66            66       ctx-rh-transversetemporal   \n",
       "67            67                   ctx-rh-insula   \n",
       "\n",
       "                             ggseg Hemisphere              Base_Region  \n",
       "0                  ctx-lh-bankssts       Left                 bankssts  \n",
       "1   ctx-lh-caudalanteriorcingulate       Left  caudalanteriorcingulate  \n",
       "2       ctx-lh-caudalmiddlefrontal       Left      caudalmiddlefrontal  \n",
       "3                    ctx-lh-cuneus       Left                   cuneus  \n",
       "4                ctx-lh-entorhinal       Left               entorhinal  \n",
       "..                             ...        ...                      ...  \n",
       "63            ctx-rh-supramarginal      Right            supramarginal  \n",
       "64              ctx-rh-frontalpole      Right              frontalpole  \n",
       "65             ctx-rh-temporalpole      Right             temporalpole  \n",
       "66       ctx-rh-transversetemporal      Right       transversetemporal  \n",
       "67                   ctx-rh-insula      Right                   insula  \n",
       "\n",
       "[68 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_region_lookup = pd.read_csv(\"Brain_Region_info.csv\", index_col=False).reset_index(drop=True)\n",
    "\n",
    "brain_region_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this lookup table shows, the first column corresponds to the left banks of the superior temporal sulcus (bankssts), which is designated with the brain region name `ctx-lh-bankssts`. The `Base_Region` column denotes the unique brain region names, each of which has a left and right hemisphere component. We can get this into a list that we'll iterate over for each subject later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['postcentral', 'frontalpole', 'entorhinal', 'inferiortemporal', 'precuneus', 'caudalmiddlefrontal', 'parsopercularis', 'supramarginal', 'fusiform', 'superiortemporal', 'inferiorparietal', 'parstriangularis', 'posteriorcingulate', 'temporalpole', 'medialorbitofrontal', 'rostralanteriorcingulate', 'middletemporal', 'pericalcarine', 'bankssts', 'precentral', 'insula', 'superiorparietal', 'parsorbitalis', 'isthmuscingulate', 'lateraloccipital', 'caudalanteriorcingulate', 'cuneus', 'paracentral', 'superiorfrontal', 'transversetemporal', 'parahippocampal', 'lateralorbitofrontal', 'rostralmiddlefrontal', 'lingual']\n"
     ]
    }
   ],
   "source": [
    "base_regions = list(set(brain_region_lookup.Base_Region.tolist()))\n",
    "\n",
    "# Print the names of our 34 cortical brain regions\n",
    "print(base_regions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try computing `di_gaussian` for the left and right `transversetemporal` cortex for subject `100307`.\n",
    "To achieve this, we'll need to find the row number (index) for the left and right `transversetemporal` regions in `brain_region_lookup` and then subset the 68x1200 array to just these two rows, yielding a 2x1200 array as the input dataset to a new `Calculator` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left index:  32\n",
      "Right index:  66\n"
     ]
    }
   ],
   "source": [
    "# Find left and right transversetemporal indices\n",
    "left_index = brain_region_lookup.query(\"Base_Region == 'transversetemporal' & Hemisphere == 'Left'\").Region_Index.tolist()[0]\n",
    "right_index = brain_region_lookup.query(\"Base_Region == 'transversetemporal' & Hemisphere == 'Right'\").Region_Index.tolist()[0]\n",
    "    \n",
    "print(\"Left index: \", left_index)\n",
    "print(\"Right index: \", right_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1200)\n"
     ]
    }
   ],
   "source": [
    "# Subset the subject_data numpy array to just left_index and right_index\n",
    "left_TS = subject_data[left_index,:].reshape(1, -1)\n",
    "right_TS = subject_data[right_index,:].reshape(1, -1)\n",
    "\n",
    "# Combine left_TS and right_TS into a 2 by 1200 numpy array\n",
    "bilateral_arr_to_compute = np.concatenate((left_TS, right_TS), axis=0)\n",
    "\n",
    "# Print the dimensions of the bilateral_arr_to_compute array\n",
    "print(bilateral_arr_to_compute.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new 2x1200 array contains the left hemisphere in the first row and right hemisphere in the second row, which is how we will format all brain regions across all subjects for consistency.\n",
    "We can then compute the `di_gaussian` SPI between the left and right hemispheres for this subject as we did with the randomly generated `NumPy` arrays above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing [None: di_gaussian]: 100%|██████████| 1/1 [00:00<00:00, 13.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration file: DI_Gaussian_config.yaml\n",
      "*** Importing module .statistics.infotheory\n",
      "[0] Adding SPI .statistics.infotheory.DirectedInfo(x,y,{'estimator': 'gaussian'})...\n",
      "Succesfully initialised SPI with identifier \"di_gaussian\" and labels ['unsigned', 'infotheory', 'temporal', 'directed', 'linear']\n",
      "Number of SPIs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>spi</th>\n",
       "      <th colspan=\"2\" halign=\"left\">di_gaussian</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <th>proc-0</th>\n",
       "      <th>proc-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>proc-0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.107727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proc-1</th>\n",
       "      <td>0.114898</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "spi     di_gaussian          \n",
       "process      proc-0    proc-1\n",
       "proc-0          NaN  0.107727\n",
       "proc-1     0.114898       NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc = Calculator(configfile=\"DI_Gaussian_config.yaml\")\n",
    "calc.load_dataset(bilateral_arr_to_compute)\n",
    "calc.compute()\n",
    "\n",
    "# Print the results table\n",
    "calc.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `proc-0` refers to the left hemisphere and `proc-1` refers to the right hemisphere.\n",
    "This format isn't the most conducive to combining across subjects and brain regions, so we can reshape it to be in a long format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hemi_from</th>\n",
       "      <th>Hemi_to</th>\n",
       "      <th>value</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Brain_Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.114898</td>\n",
       "      <td>100307</td>\n",
       "      <td>transversetemporal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.107727</td>\n",
       "      <td>100307</td>\n",
       "      <td>transversetemporal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hemi_from Hemi_to     value Sample_ID        Brain_Region\n",
       "1     right    left  0.114898    100307  transversetemporal\n",
       "2      left   right  0.107727    100307  transversetemporal"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract directed information results as the calc.table object\n",
    "ROI_DI_data = deepcopy(calc.table)\n",
    "\n",
    "# Flatten the MultiIndex columns to just the process IDs\n",
    "ROI_DI_data.columns = ROI_DI_data.columns.get_level_values(1)\n",
    "\n",
    "# Pivot and clean up ROI directed information data\n",
    "ROI_DI_data = (ROI_DI_data\n",
    "                .reset_index(level=0) # Convert index to column\n",
    "                .rename(columns={\"index\": \"Hemi_from\"}) # Rename index as first hemisphere\n",
    "                .melt(id_vars=\"Hemi_from\") # Pivot data from wide to long\n",
    "                .rename(columns={\"process\": \"Hemi_to\"}) # Rename hemisphere receiving the connection\n",
    "                .query(\"Hemi_from != Hemi_to\") # Remove self-connections\n",
    "                .assign(Sample_ID = \"100307\",\n",
    "                        Brain_Region = \"transversetemporal\")\n",
    "                .assign(Hemi_from=lambda x: x['Hemi_from'].replace({'proc-0': 'left', 'proc-1': 'right'}),\n",
    "                        Hemi_to=lambda x: x['Hemi_to'].replace({'proc-0': 'left', 'proc-1': 'right'}))\n",
    "                )\n",
    "\n",
    "# Print the resulting dataframe\n",
    "ROI_DI_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a helper function for directed information computation\n",
    "\n",
    "Next, we'll define a helper function to compute directed information with a Gaussian density estimator for a given pair of brain regions. \n",
    "This function will read in the name of a brain region (e.g., `transversetemporal`, as above), the brain region lookup table we loaded above, the given subject's ID and region-wise time-series data, and a `basecalc` object.\n",
    "It will repeat the same steps as above and output the resulting reshaped `ROI_DI_data` dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to read in a base region (e.g., bankssts) and compute\n",
    "# Directed information from left to right and from right to left\n",
    "def compute_DI_for_region(base_region, brain_region_lookup, subject_ID, subject_data, basecalc):\n",
    "    left_index = brain_region_lookup.query(\"Base_Region == @base_region & Hemisphere == 'Left'\").Region_Index.tolist()[0]\n",
    "    right_index = brain_region_lookup.query(\"Base_Region == @base_region & Hemisphere == 'Right'\").Region_Index.tolist()[0]\n",
    "    \n",
    "    # Subset the subject_data numpy array to just left_index and right_index\n",
    "    left_TS = subject_data[left_index,:].reshape(1, -1)\n",
    "    right_TS = subject_data[right_index,:].reshape(1, -1)\n",
    "    \n",
    "    # Combine left_TS and right_TS into a 2 by 1200 numpy array\n",
    "    bilateral_arr_to_compute = np.concatenate((left_TS, right_TS), axis=0)\n",
    "    \n",
    "    # Compute directed information for these two time-series\n",
    "    calc = deepcopy(basecalc)\n",
    "    calc.load_dataset(bilateral_arr_to_compute)\n",
    "    calc.compute()\n",
    "    \n",
    "    # Extract directed information results as the calc.table object\n",
    "    ROI_DI_data = calc.table \n",
    "    \n",
    "    # Flatten the MultiIndex columns to just the process IDs\n",
    "    ROI_DI_data.columns = ROI_DI_data.columns.get_level_values(1)\n",
    "    \n",
    "    # Pivot and clean up ROI directed information data\n",
    "    ROI_DI_data = (ROI_DI_data\n",
    "                   .reset_index(level=0) # Convert index to column\n",
    "                   .rename(columns={\"index\": \"Hemi_from\"}) # Rename index as first hemisphere\n",
    "                   .melt(id_vars=\"Hemi_from\") # Pivot data from wide to long\n",
    "                   .rename(columns={\"process\": \"Hemi_to\"}) # Rename hemisphere receiving the connection\n",
    "                   .query(\"Hemi_from != Hemi_to\") # Remove self-connections\n",
    "                   .assign(Sample_ID = subject_ID,\n",
    "                           Brain_Region = base_region)\n",
    "                    .assign(Hemi_from=lambda x: x['Hemi_from'].replace({'proc-0': 'left', 'proc-1': 'right'}),\n",
    "                            Hemi_to=lambda x: x['Hemi_to'].replace({'proc-0': 'left', 'proc-1': 'right'}))\n",
    "                   )\n",
    "    \n",
    "    # Return the final dataframe for this region\n",
    "    return ROI_DI_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute DI across all regions and all participants\n",
    "\n",
    "The last step is to iterate over each of the HCP100 subjects and then within each subject, iterate over all 34 brain regions to compute `di_gaussian` between the left and right hemispheres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a base Calculator object\n",
    "basecalc = Calculator(configfile=\"DI_Gaussian_config.yaml\")\n",
    "\n",
    "# Initialise a list for all HCP100 directed information\n",
    "HCP100_DI_list = []\n",
    "\n",
    "# Iterate over each of the 100 \n",
    "for subject_filepath in glob.glob(f'{data_dir}/*.npy'):\n",
    "    \n",
    "    # Subset to basename for file\n",
    "    subject_npy = os.path.basename(subject_filepath)\n",
    "    \n",
    "    # Get sample ID substring\n",
    "    subject_ID = subject_npy.replace(\".npy\", \"\")\n",
    "    \n",
    "    # Load in subject's ROI time series from numpy binary file\n",
    "    subject_data = np.load(data_dir + subject_npy)\n",
    "    \n",
    "    # Initialise a list to store the directed information for each region between left and right hemispheres\n",
    "    subject_DI_list = []\n",
    "    \n",
    "    # Apply compute_DI_for_region to each base region\n",
    "    for base_region in base_regions:\n",
    "        ROI_DI_data = compute_DI_for_region(base_region = base_region,\n",
    "                                            brain_region_lookup = brain_region_lookup,\n",
    "                                            subject_ID = subject_ID,\n",
    "                                            subject_data = subject_data,\n",
    "                                            basecalc = basecalc)\n",
    "        subject_DI_list.append(ROI_DI_data)\n",
    "    \n",
    "    # Concatenate dataframes across regions\n",
    "    subject_DI = pd.concat(subject_DI_list, axis=0)\n",
    "    \n",
    "    HCP100_DI_list.append(subject_DI)\n",
    "\n",
    "# Combine all the dataframes in the HC100_DI_list into a single dataframe\n",
    "HCP100_DI = (pd.concat(HCP100_DI_list, axis=0)\n",
    "             .rename(columns={\"value\": \"di_gaussian\"})\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hemi_from</th>\n",
       "      <th>Hemi_to</th>\n",
       "      <th>di_gaussian</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Brain_Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.185312</td>\n",
       "      <td>298051</td>\n",
       "      <td>postcentral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.159081</td>\n",
       "      <td>298051</td>\n",
       "      <td>postcentral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.023387</td>\n",
       "      <td>298051</td>\n",
       "      <td>frontalpole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.028484</td>\n",
       "      <td>298051</td>\n",
       "      <td>frontalpole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.016775</td>\n",
       "      <td>298051</td>\n",
       "      <td>entorhinal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hemi_from Hemi_to  di_gaussian Sample_ID Brain_Region\n",
       "1     right    left     1.185312    298051  postcentral\n",
       "2      left   right     1.159081    298051  postcentral\n",
       "1     right    left     0.023387    298051  frontalpole\n",
       "2      left   right     0.028484    298051  frontalpole\n",
       "1     right    left     0.016775    298051   entorhinal"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the head of this dataframe\n",
    "HCP100_DI.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the results to a CSV file for downstream analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCP100_DI.to_csv(\"data/HCP100_Directed_Information.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
